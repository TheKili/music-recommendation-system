{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import multiprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get & Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get & Format Data from content.csv\n",
    "content = pd.read_csv('../raw_data/content.csv')\n",
    "content_df = content.groupby('track_id', as_index=False).first()\n",
    "content_df = content_df.reset_index(drop=True)\n",
    "# content_df['track_name'] = content_df['track_name'].astype(str)\n",
    "# content_df['artists'] = content_df['artists'].astype(str)\n",
    "content_df = content_df[['track_id', 'track_name', 'artists']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.0-999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.1000-1999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.2000-2999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.3000-3999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.4000-4999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.5000-5999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.6000-6999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.7000-7999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.8000-8999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.9000-9999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.10000-10999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.11000-11999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.12000-12999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.13000-13999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.14000-14999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.15000-15999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.16000-16999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.17000-17999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.18000-18999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.19000-19999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.20000-20999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.21000-21999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.22000-22999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.23000-23999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.24000-24999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.25000-25999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.26000-26999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.27000-27999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.28000-28999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.29000-29999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.30000-30999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.31000-31999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.32000-32999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.33000-33999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.34000-34999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.35000-35999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.36000-36999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.37000-37999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.38000-38999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.39000-39999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.40000-40999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.41000-41999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.42000-42999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.43000-43999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.44000-44999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.45000-45999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.46000-46999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.47000-47999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.48000-48999.json\n",
      "/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.49000-49999.json\n"
     ]
    }
   ],
   "source": [
    "#Print Colab-Slices Locations (to check if they're correct)\n",
    "\n",
    "slice_amount = 5\n",
    "for i in range(slice_amount):\n",
    "    #json_file_paths.append(f'../raw_data/playlist_data/mpd.slice.{i*1000}-{999+ i * 1000}.json')\n",
    "    print((f'/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.{i*1000}-{999+ i * 1000}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "small_data_loc = \"../raw_data/playlist_data/\"\n",
    "all_data_loc = \"/mnt/d/spotify_million_playlist_dataset/data\"\n",
    "\n",
    "json_file_paths = [f'/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.{i*1000}-{999+ i * 1000}.json'\n",
    "                    for i in range(slice_amount)]\n",
    "\n",
    "# Read the JSON file\n",
    "json_data = []\n",
    "for i in range(len(json_file_paths)):\n",
    "    with open(json_file_paths[i], 'r') as file:\n",
    "        json_data.append(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Specify the path to your JSON file\n",
    "# json_file_paths = [f'/mnt/d/spotify_million_playlist_dataset/data/mpd.slice.{i*1000}-{999+ i * 1000}.json'\n",
    "#                     for i in range(slice_amount)]\n",
    "\n",
    "# def load_json_file(file_path):\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         return json.load(file)\n",
    "\n",
    "# pool = multiprocessing.Pool()\n",
    "# json_data = pool.map(load_json_file, json_file_paths)\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get Track Sum per Batch\n",
    "# track_sum_per_batch = 0\n",
    "# batch = 0\n",
    "# for i in range(len(json_data[batch]['playlists'])):\n",
    "#     playlist_i = json_data[batch]['playlists'][i]['tracks']\n",
    "#     track_sum_per_batch += len(playlist_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get Track Sum\n",
    "# track_sum = 0\n",
    "# for i in range(len(json_data)):\n",
    "#     json_i = json_data[i]['playlists']\n",
    "#     for j in range(len(json_i)):\n",
    "#         playlist = json_data[i]['playlists'][j]['tracks']\n",
    "#         track_sum += len(playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get Track List Per Batch\n",
    "\n",
    "# tracklist_per_batch = []\n",
    "# batch = 0\n",
    "\n",
    "# for i in range(len(json_data[batch]['playlists'])):\n",
    "#     playlist_i = json_data[batch]['playlists'][i]['tracks']\n",
    "#     for j in range(len(playlist_i)):\n",
    "#         tracklist_per_batch.append(f'{i}' + ': ' + playlist_i[j]['artist_name'] + ' - ' + playlist_i[j]['track_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# #Get Track List\n",
    "\n",
    "\n",
    "# tracklist = []\n",
    "# for k in range (len(json_data)):\n",
    "#     for i in range(len(json_data[k]['playlists'])):\n",
    "#         playlist_i = json_data[k]['playlists'][i]['tracks']\n",
    "#         for j in range(len(playlist_i)):\n",
    "#             tracklist.append(f'{k*1000 + i}' + ' ||| ' + playlist_i[j]['artist_name']\n",
    "#                              + ' ||| ' + playlist_i[j]['track_name'] + ' ||| ' + str(playlist_i[j]['track_uri']))\n",
    "            \n",
    "# #Split Tracklist (to create DF)\n",
    "\n",
    "# split_tracklist = [item.split(' ||| ') for item in tracklist]\n",
    "\n",
    "# for i in range(len(split_tracklist)):\n",
    "#     split_tracklist[i][3] = split_tracklist[i][3].replace('spotify:track:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklist = [f'{k*1000 + i} ||| {track[\"artist_name\"]} ||| {track[\"track_name\"]} ||| {track[\"track_uri\"].replace(\"spotify:track:\", \"\")}'\n",
    "             for k, data in enumerate(json_data)\n",
    "             for i, playlist in enumerate(data['playlists'])\n",
    "             for track in playlist['tracks']]\n",
    "\n",
    "split_tracklist = [item.split(' ||| ') for item in tracklist]\n",
    "tracklist_df = pd.DataFrame(split_tracklist, columns=['playlist_number', 'artist_name', 'track_name', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DF\n",
    "# tracklist_df = pd.DataFrame(split_tracklist, columns=['playlist_number', 'artist_name', 'track_name', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge DFs on Track_ID (to get only the Tracks available in both Datasets)\n",
    "\n",
    "merged_df = pd.merge(tracklist_df, content_df, on='track_id', how='inner')\n",
    "clean_df = merged_df.drop(columns=['track_name_y', 'artists'])\n",
    "clean_unique = clean_df.groupby('track_id', as_index=False).first()\n",
    "merged_unique = clean_unique.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create Dict per Track (to get all Playlists containing the Track)\n",
    "# #Not operational\n",
    "\n",
    "# trackdict = {}\n",
    "# for i in range(10):\n",
    "#     track = tracklist[i].split(' ||| ', tracklist[i])[1]\n",
    "#     trackdict[f'{i}'] = []\n",
    "#     for j in range(len(tracklist)):\n",
    "#         if track in tracklist[j]:\n",
    "#             trackdict[f'{i}'].append(tracklist[j].split(' ||| ')[0])\n",
    "#     print(f'done with track number {i}')\n",
    "# trackdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Track_to_Playlist_Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df = clean_df.groupby('track_id', as_index=False).agg({'playlist_number': list})\n",
    "playlist_df = playlist_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all playlists containing the track\n",
    "\n",
    "# Specify the track_id you want to locate\n",
    "target_track_id = '7zkLpY72g6lKQbiHDqri1S'\n",
    "\n",
    "# Use loc[] to locate the rows with the specific track_id\n",
    "specific_rows = playlist_df.loc[playlist_df['track_id'] == target_track_id]\n",
    "\n",
    "playlistlist = specific_rows['playlist_number'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One Hot Encode playlists into df\n",
    "\n",
    "# # Get all unique playlists\n",
    "# unique_playlists = []\n",
    "# for i in range(len(playlist_df)):\n",
    "#     unique_playlists += playlist_df['playlist_number'][i]\n",
    "# unique_playlists = list(set(unique_playlists))\n",
    "# unique_playlists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_playlists = playlist_df['playlist_number'].explode().unique()\n",
    "unique_playlists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create track_to_playlist_matrix with shape:\n",
    "# (len(playlist_df) = Amount of unique Tracks, len(unique_playlists) = Amount of unique Playlists)\n",
    "# Index: (playlist_df['track_id'], unique_playlists)\n",
    "\n",
    "track_to_playlist_matrix = np.zeros((playlist_df.shape[0], len(unique_playlists)))\n",
    "\n",
    "for i, playlists in enumerate(playlist_df['playlist_number']):\n",
    "    track_to_playlist_matrix[i, np.searchsorted(unique_playlists, playlists)] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Create a Track_Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Funktionen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_matrix_function(track_to_playlist_matrix):\n",
    "    # Create track_matrix with shape:\n",
    "    # (len(playlist_df) = Amount of unique Tracks)**2\n",
    "    # Index: (playlist_df['track_id'], playlist_df['track_id'])\n",
    "    # with track_matrix[i][j] = amount of same playlists for track i and track j\n",
    "    track_matrix = track_to_playlist_matrix @ track_to_playlist_matrix.T\n",
    "    return track_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_matrix_function(track_to_playlist_matrix):\n",
    "    # Convert track_to_playlist_matrix to sparse CSR matrix\n",
    "    sparse_track_to_playlist_matrix = sp.csr_matrix(track_to_playlist_matrix)\n",
    "\n",
    "    # Perform matrix multiplication using sparse matrix operations\n",
    "    sparse_track_matrix = sparse_track_to_playlist_matrix @ sparse_track_to_playlist_matrix.T\n",
    "\n",
    "    # Convert the sparse_track_matrix back to a dense matrix if needed\n",
    "    dense_track_matrix = sparse_track_matrix.toarray()\n",
    "    \n",
    "    return dense_track_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newnew_matrix_function(track_to_playlist_matrix, chunk_size=10):\n",
    "    num_tracks = track_to_playlist_matrix.shape[0]\n",
    "    num_chunks = int(np.ceil(num_tracks / chunk_size))\n",
    "\n",
    "    # Initialize an empty sparse matrix to store the track matrix\n",
    "    sparse_track_matrix = sp.csr_matrix((num_tracks, num_tracks))\n",
    "\n",
    "    for chunk_idx in range(num_chunks):\n",
    "        # Determine the range of track indices for the current chunk\n",
    "        start_idx = chunk_idx * chunk_size\n",
    "        end_idx = min((chunk_idx + 1) * chunk_size, num_tracks)\n",
    "\n",
    "        # Extract the chunk of track-to-playlist matrix\n",
    "        chunk_track_to_playlist_matrix = track_to_playlist_matrix[start_idx:end_idx]\n",
    "\n",
    "        # Convert the chunk to a sparse CSR matrix\n",
    "        sparse_chunk_track_to_playlist = sp.csr_matrix(chunk_track_to_playlist_matrix)\n",
    "\n",
    "        # Perform matrix multiplication using sparse matrix operations\n",
    "        sparse_chunk_track_matrix = sparse_chunk_track_to_playlist @ sparse_chunk_track_to_playlist.T\n",
    "\n",
    "        # Accumulate the results in the overall track matrix\n",
    "        sparse_track_matrix[start_idx:end_idx, start_idx:end_idx] = sparse_chunk_track_matrix\n",
    "        \n",
    "    # Convert the sparse track matrix back to a dense matrix if needed\n",
    "    dense_track_matrix = sparse_track_matrix.toarray()\n",
    "\n",
    "    return dense_track_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Figuring out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Explore Datatypes and Multiplication types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272403840"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_to_playlist_matrix.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68100960"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_to_playlist_matrix_int16 = track_to_playlist_matrix.astype(np.int16)\n",
    "track_to_playlist_matrix_int16.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]], dtype=int16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_matrix_int16 = track_to_playlist_matrix_int16 @ track_to_playlist_matrix_int16.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np multiplier instead\n",
    "\n",
    "track_matrix_int16_np = np.dot(track_to_playlist_matrix_int16,track_to_playlist_matrix_int16.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 3., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 2., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 2., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 2.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_matrix = track_to_playlist_matrix @ track_to_playlist_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np multiplier instead\n",
    "\n",
    "track_matrix_np = np.dot(track_to_playlist_matrix,track_to_playlist_matrix.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Use Dask to parallelize the matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input matrices as Dask arrays\n",
    "#track_to_playlist_da = da.from_array(track_to_playlist_matrix, chunks=chunk_size)\n",
    "chunk_size_mb = 100  \n",
    "chunk_size_bytes = chunk_size_mb * 2**20  \n",
    "track_to_playlist_da = da.from_array(track_to_playlist_matrix, chunks=chunk_size_bytes)\n",
    "x_transposed = track_to_playlist_da.transpose()\n",
    "track_to_playlist_da_T = x_transposed.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication\n",
    "result = da.dot(track_to_playlist_da, track_to_playlist_da_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the result\n",
    "result = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    result = result.compute()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 276.27 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit get_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array.core.Array"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Get Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2110.63 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit old_matrix_function(track_to_playlist_matrix_int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2241.07 MiB, increment: 3.95 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit new_matrix_function(track_to_playlist_matrix_int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2235.46 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit newnew_matrix_function(track_to_playlist_matrix_int16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Normalize n Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give maximum value in matrix\n",
    "max_value = np.max(track_matrix)\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Matrix\n",
    "def normalize(track_matrix):\n",
    "    #normalize track_matrix\n",
    "    for i in range(len(track_matrix)):\n",
    "        if track_matrix[i, i] != 1:\n",
    "            # Normalize values\n",
    "            track_matrix[i, :] /= track_matrix[i, i]\n",
    "            track_matrix[:, i] /= track_matrix[i, i]\n",
    "    return track_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = normalize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 0 B </td>\n",
       "                        <td> 0 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (0, 0) </td>\n",
       "                        <td> (0, 0) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 4 Tasks </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<sum-aggregate, shape=(0, 0), dtype=float64, chunksize=(0, 0), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colab_recommendations (track_matrix: np.ndarray, track_id):\n",
    "    \"\"\"\n",
    "    Returns a list of recommended tracks for a given track_id\n",
    "    Based on track_matrix\n",
    "    (aka tracks that are in the same playlists as the given track_id)\n",
    "    \"\"\"\n",
    "    idx = playlist_df.loc[playlist_df['track_id'] == target_track_id].index[0]\n",
    "    track_matrix[idx]\n",
    "    sorted_indices = np.argsort(-track_matrix[idx])\n",
    "    sorted_values = track_matrix[idx][sorted_indices]\n",
    "    merged_array = np.column_stack((sorted_indices, sorted_values))\n",
    "    return merged_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colab_recommendations(track_matrix: np.ndarray, target_track_id):\n",
    "    \"\"\"\n",
    "    Returns a list of recommended tracks for a given track_id\n",
    "    Based on track_matrix\n",
    "    (aka tracks that are in the same playlists as the given track_id)\n",
    "    \"\"\"\n",
    "    idx = np.where(playlist_df['track_id'] == target_track_id)[0][0]\n",
    "    sorted_indices = np.argsort(-track_matrix[idx])\n",
    "    merged_array = np.column_stack((sorted_indices, track_matrix[idx][sorted_indices]))\n",
    "    return merged_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hier könnten wir die daten normalisieren, also alle werte auf 0-1 bringen   \n",
    "wenn ein track in vielen verschiedenen playlists landet   \n",
    "(aktuelles maximum: 139x) könnte eine cooccurence weniger aussagekräftig sein   \n",
    "dazu: jede cooccurence teilen   \n",
    "durch: Wert auf der Diagonalen (also wie oft ein track in der playlist vorkommt)   \n",
    "dann weighting Wert Alpha als Variable einbauen   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
